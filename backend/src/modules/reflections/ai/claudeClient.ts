import Anthropic from '@anthropic-ai/sdk';
import { config } from '../../../config/env';
import {
  COGNITIVE_REFRAMING_SYSTEM_PROMPT,
  FOLLOW_UP_CONVERSATION_CONTEXT,
  FINAL_RULES_REMINDER,
  getEmotionSpecificPrompt,
  getCounselingStylePrompt,
  EmotionTag,
  CounselingStyle,
} from './prompts';

const anthropic = new Anthropic({
  apiKey: config.anthropicApiKey,
});

const MODEL = 'claude-opus-4-20250514';
const MAX_TOKENS = 8192;
const TEMPERATURE = 0.7;

// Prefill: assistant ì‘ë‹µì˜ ì‹œì‘ì„ ìœ ë„í•˜ì—¬ ë»”í•œ ìœ„ë¡œ ëŒ€ì‹  êµ¬ì²´ì  ê³µê°ìœ¼ë¡œ ì‹œì‘í•˜ê²Œ í•¨
const ASSISTANT_PREFILL = 'ë‹¹ì‹ ì´ ë§ì”€í•˜ì‹ ';

console.log(`[ClaudeClient] Initialized with model=${MODEL}, maxTokens=${MAX_TOKENS}, temperature=${TEMPERATURE}`);

export interface Message {
  role: 'user' | 'assistant';
  content: string;
}

export interface StreamChunk {
  type: 'content_block_delta' | 'message_stop';
  delta?: {
    type: 'text_delta';
    text: string;
  };
}

/**
 * ìºì‹œ ì‚¬ìš©ëŸ‰ ë¡œê¹…
 * Prompt Caching íˆíŠ¸/ë¯¸ìŠ¤ ì—¬ë¶€ì™€ ë¹„ìš© ì ˆê° íš¨ê³¼ë¥¼ ì½˜ì†”ì— ì¶œë ¥
 */
function logCacheUsage(usage: {
  input_tokens: number;
  output_tokens: number;
  cache_creation_input_tokens?: number;
  cache_read_input_tokens?: number;
}) {
  const cacheWrite = usage.cache_creation_input_tokens || 0;
  const cacheRead = usage.cache_read_input_tokens || 0;
  const uncached = usage.input_tokens;

  if (cacheRead > 0) {
    // Opus 4 ê¸°ì¤€: ìºì‹œ ì½ê¸°ëŠ” $1.5/1M (ì›ë˜ $15/1M ëŒ€ë¹„ 90% ì ˆê°)
    const savedTokens = cacheRead;
    const savedCostUSD = (savedTokens / 1_000_000) * (15 - 1.5);
    const savedCostKRW = Math.round(savedCostUSD * 1450);
    console.log(`[Cache] âœ… HIT â€” cached=${cacheRead} tokens, uncached=${uncached}, output=${usage.output_tokens} | ì ˆê°: ~${savedCostKRW}ì›`);
  } else if (cacheWrite > 0) {
    console.log(`[Cache] ğŸ“ WRITE â€” cached=${cacheWrite} tokens (ë‹¤ìŒ ìš”ì²­ë¶€í„° ìºì‹œ ì ìš©), uncached=${uncached}, output=${usage.output_tokens}`);
  } else {
    console.log(`[Cache] âŒ MISS â€” input=${uncached}, output=${usage.output_tokens} (ìºì‹œ ë¯¸ì ìš©)`);
  }
}

/**
 * ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ Prompt Caching í˜•ì‹ìœ¼ë¡œ ë³€í™˜
 * ë³€í•˜ì§€ ì•ŠëŠ” ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ëŠ” ìºì‹œí•˜ê³ , ë™ì  ë¶€ë¶„ì€ ë³„ë„ ë¸”ë¡ìœ¼ë¡œ ë¶„ë¦¬
 */
function buildCachedSystemPrompt(
  emotion?: EmotionTag,
  counselingStyle?: CounselingStyle,
  pastContext?: string,
  isFollowUp?: boolean
): Anthropic.Messages.TextBlockParam[] {
  // ë¸”ë¡ 1: í•µì‹¬ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ëª¨ë“  ìš”ì²­ì— ë™ì¼ â†’ ìºì‹œ ëŒ€ìƒ)
  const blocks: Anthropic.Messages.TextBlockParam[] = [
    {
      type: 'text',
      text: COGNITIVE_REFRAMING_SYSTEM_PROMPT,
      cache_control: { type: 'ephemeral' },
    } as Anthropic.Messages.TextBlockParam,
  ];

  // ë¸”ë¡ 2: ë™ì  ì»¨í…ìŠ¤íŠ¸ (ëŒ€í™” ìƒíƒœì— ë”°ë¼ ë³€í•¨)
  const dynamicParts: string[] = [];

  if (isFollowUp) {
    dynamicParts.push(FOLLOW_UP_CONVERSATION_CONTEXT);
  }
  if (emotion) {
    dynamicParts.push(getEmotionSpecificPrompt(emotion));
  }
  const stylePrompt = getCounselingStylePrompt(counselingStyle);
  if (stylePrompt) {
    dynamicParts.push(stylePrompt);
  }
  if (pastContext) {
    dynamicParts.push(pastContext);
  }
  dynamicParts.push(FINAL_RULES_REMINDER);

  if (dynamicParts.length > 0) {
    blocks.push({
      type: 'text',
      text: dynamicParts.join('\n\n'),
    });
  }

  return blocks;
}

/**
 * Claude APIë¥¼ ì‚¬ìš©í•œ ì¸ì§€ ì¬êµ¬ì¡°í™” ì‘ë‹µ ìƒì„±
 */
export class ClaudeClient {
  /**
   * ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„±
   *
   * @param messages - ëŒ€í™” íˆìŠ¤í† ë¦¬
   * @param emotion - ì„ íƒì  ê°ì • íƒœê·¸
   * @param onChunk - ê° í…ìŠ¤íŠ¸ ì²­í¬ë¥¼ ë°›ì„ ì½œë°±
   * @returns ì „ì²´ ì‘ë‹µ í…ìŠ¤íŠ¸ ë° ì‚¬ìš©ëœ í† í° ìˆ˜
   */
  async streamReframingResponse(
    messages: Message[],
    emotion?: EmotionTag,
    onChunk?: (text: string) => void,
    pastContext?: string,
    counselingStyle?: CounselingStyle
  ): Promise<{ text: string; tokensUsed: number }> {
    const isFollowUp = messages.length > 1;
    const systemBlocks = buildCachedSystemPrompt(emotion, counselingStyle, pastContext, isFollowUp);

    let fullText = '';
    let inputTokens = 0;
    let outputTokens = 0;
    let cacheCreateTokens = 0;
    let cacheReadTokens = 0;

    const totalSystemChars = systemBlocks.reduce((sum, b) => sum + b.text.length, 0);
    console.log(`[Claude] model=${MODEL}, systemPrompt=${totalSystemChars}chars (${systemBlocks.length} blocks), messages=${messages.length}, isFollowUp=${isFollowUp}`);

    const apiMessages = [
      ...messages.map((msg) => ({
        role: msg.role as 'user' | 'assistant',
        content: msg.content,
      })),
      { role: 'assistant' as const, content: ASSISTANT_PREFILL },
    ];

    const stream = await anthropic.messages.stream({
      model: MODEL,
      max_tokens: MAX_TOKENS,
      temperature: TEMPERATURE,
      system: systemBlocks,
      messages: apiMessages,
    });

    // Prefill í…ìŠ¤íŠ¸ë¥¼ ì‘ë‹µ ì•ì— í¬í•¨
    fullText = ASSISTANT_PREFILL;
    if (onChunk) {
      onChunk(ASSISTANT_PREFILL);
    }

    // ìŠ¤íŠ¸ë¦¼ ì´ë²¤íŠ¸ ì²˜ë¦¬
    stream.on('text', (text) => {
      fullText += text;
      if (onChunk) {
        onChunk(text);
      }
    });

    stream.on('message', (message) => {
      if (message.usage) {
        inputTokens = message.usage.input_tokens;
        outputTokens = message.usage.output_tokens;
        // @ts-expect-error â€” cache fields exist in API response but not yet in SDK types
        cacheCreateTokens = message.usage.cache_creation_input_tokens || 0;
        // @ts-expect-error â€” cache fields exist in API response but not yet in SDK types
        cacheReadTokens = message.usage.cache_read_input_tokens || 0;
      }
    });

    // ìŠ¤íŠ¸ë¦¼ ì™„ë£Œ ëŒ€ê¸°
    await stream.finalMessage();

    logCacheUsage({
      input_tokens: inputTokens,
      output_tokens: outputTokens,
      cache_creation_input_tokens: cacheCreateTokens,
      cache_read_input_tokens: cacheReadTokens,
    });

    return {
      text: fullText,
      tokensUsed: inputTokens + outputTokens,
    };
  }

  /**
   * ë¹„ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„± (í…ŒìŠ¤íŠ¸ìš©)
   */
  async getReframingResponse(
    messages: Message[],
    emotion?: EmotionTag,
    pastContext?: string,
    counselingStyle?: CounselingStyle
  ): Promise<{ text: string; tokensUsed: number }> {
    const isFollowUp = messages.length > 1;
    const systemBlocks = buildCachedSystemPrompt(emotion, counselingStyle, pastContext, isFollowUp);

    const totalSystemChars = systemBlocks.reduce((sum, b) => sum + b.text.length, 0);
    console.log(`[Claude] model=${MODEL}, systemPrompt=${totalSystemChars}chars (${systemBlocks.length} blocks), messages=${messages.length}, isFollowUp=${isFollowUp}`);

    const apiMessages = [
      ...messages.map((msg) => ({
        role: msg.role as 'user' | 'assistant',
        content: msg.content,
      })),
      { role: 'assistant' as const, content: ASSISTANT_PREFILL },
    ];

    const response = await anthropic.messages.create({
      model: MODEL,
      max_tokens: MAX_TOKENS,
      temperature: TEMPERATURE,
      system: systemBlocks,
      messages: apiMessages,
    });

    const usage = response.usage as {
      input_tokens: number;
      output_tokens: number;
      cache_creation_input_tokens?: number;
      cache_read_input_tokens?: number;
    };
    logCacheUsage(usage);

    const textContent = response.content.find((block) => block.type === 'text');
    const rawText = textContent && 'text' in textContent ? textContent.text : '';
    const text = ASSISTANT_PREFILL + rawText;

    return {
      text,
      tokensUsed: usage.input_tokens + usage.output_tokens,
    };
  }

  /**
   * ìƒë‹´ ë§ˆë¬´ë¦¬ ì‹œ ì¶”ì²œ ì•¡ì…˜ ìƒì„±
   *
   * ëŒ€í™” ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ë‚´ì¼ ì‹¤ì²œí•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì ì¸ í™œë™ì´ë‚˜ ë§ì„ ì¶”ì²œí•©ë‹ˆë‹¤.
   */
  async generateRecommendedAction(
    conversations: Message[],
    emotion?: EmotionTag
  ): Promise<{ text: string; tokensUsed: number }> {
    const systemPromptText = `ë‹¹ì‹ ì€ ë¶€ëª¨ì˜ ê°ì • ì§€ì› ë™ë°˜ìì…ë‹ˆë‹¤. ì§€ê¸ˆê¹Œì§€ì˜ ìƒë‹´ ëŒ€í™”ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ë‚´ì¼ ì‹¤ì²œí•  ìˆ˜ ìˆëŠ” **êµ¬ì²´ì ì¸ ì¶”ì²œ ì•¡ì…˜ 1ê°€ì§€**ë¥¼ ì œì•ˆí•´ì£¼ì„¸ìš”.

**í˜•ì‹:**
- "ë‚´ì¼ì€ [êµ¬ì²´ì ì¸ í™œë™]ì„ í•´ë³´ì„¸ìš”." ë˜ëŠ” "ë‚´ì¼ì€ ì•„ì´ì—ê²Œ '[êµ¬ì²´ì ì¸ ë§]'ì´ë¼ê³  ë§í•´ë³´ì„¸ìš”." í˜•íƒœë¡œ ì‘ì„±
- ë°˜ë“œì‹œ ëŒ€í™” ë‚´ìš©ê³¼ ê´€ë ¨ëœ ë§ì¶¤í˜• ì œì•ˆì´ì–´ì•¼ í•©ë‹ˆë‹¤
- ì§§ê³  ì‹¤ì²œ ê°€ëŠ¥í•œ ê²ƒì´ì–´ì•¼ í•©ë‹ˆë‹¤ (1-2ë¬¸ì¥)

**ì˜ˆì‹œ:**
- "ë‚´ì¼ì€ ì•„ì´ì™€ 10ë¶„ê°„ í•¨ê»˜ ê·¸ë¦¼ì„ ê·¸ë ¤ë³´ì„¸ìš”. ì™„ë²½í•˜ì§€ ì•Šì•„ë„, í•¨ê»˜í•˜ëŠ” ì‹œê°„ ìì²´ê°€ ì„ ë¬¼ì´ì—ìš”."
- "ë‚´ì¼ì€ ì•„ì´ì—ê²Œ 'ì—„ë§ˆ(ì•„ë¹ )ê°€ ì–´ì œ ì†Œë¦¬ ì§ˆëŸ¬ì„œ ë¯¸ì•ˆí•´. ë„ˆë¥¼ ì •ë§ ì‚¬ë‘í•´'ë¼ê³  ë§í•´ë³´ì„¸ìš”."
- "ë‚´ì¼ì€ í‡´ê·¼ í›„ 5ë¶„ë§Œ í˜¼ì ê¹Šê²Œ ìˆ¨ì„ ì‰¬ëŠ” ì‹œê°„ì„ ê°€ì ¸ë³´ì„¸ìš”. ë‹¹ì‹ ë„ ì‰´ ìê²©ì´ ìˆì–´ìš”."
- "ë‚´ì¼ì€ ì•„ì´ê°€ ë§í•  ë•Œ í•¸ë“œí°ì„ ë‚´ë ¤ë†“ê³  ëˆˆì„ ë§ì¶”ë©° ë“¤ì–´ë³´ì„¸ìš”. ì‘ì€ ë³€í™”ê°€ í° ì—°ê²°ì„ ë§Œë“¤ì–´ìš”."

**ê·œì¹™:**
- ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ì‘ë‹µ
- êµí›ˆì ì´ê±°ë‚˜ ì„¤êµí•˜ëŠ” í†¤ ê¸ˆì§€
- ë”°ëœ»í•˜ê³  ê²©ë ¤í•˜ëŠ” í†¤
- ì¶”ì²œ ì•¡ì…˜ë§Œ ì¶œë ¥ (ë‹¤ë¥¸ ì¸ì‚¬ë§ì´ë‚˜ ë¶€ê°€ ì„¤ëª… ì—†ì´)`;

    const response = await anthropic.messages.create({
      model: MODEL,
      max_tokens: 256,
      system: [
        {
          type: 'text',
          text: systemPromptText,
          cache_control: { type: 'ephemeral' },
        } as Anthropic.Messages.TextBlockParam,
      ],
      messages: conversations.map((msg) => ({
        role: msg.role,
        content: msg.content,
      })),
    });

    const usage = response.usage as {
      input_tokens: number;
      output_tokens: number;
      cache_creation_input_tokens?: number;
      cache_read_input_tokens?: number;
    };
    logCacheUsage(usage);

    const textContent = response.content.find((block) => block.type === 'text');
    const text = textContent && 'text' in textContent ? textContent.text : '';

    return {
      text,
      tokensUsed: usage.input_tokens + usage.output_tokens,
    };
  }

  /**
   * ê°ì • ë¶„ì„ (ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜)
   *
   * Claude APIë¥¼ ì‚¬ìš©í•œ ë” ì •êµí•œ ê°ì • ë¶„ì„ë„ ê°€ëŠ¥í•˜ì§€ë§Œ,
   * ë¹„ìš© ì ˆê°ì„ ìœ„í•´ í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ì„ì„ ë¨¼ì € ì‚¬ìš©í•©ë‹ˆë‹¤.
   */
  async analyzeEmotion(text: string): Promise<{
    emotionalTone: string;
    sentimentScore: number;
    stressLevel: number;
  }> {
    const lowerText = text.toLowerCase();

    // ê°ì • í‚¤ì›Œë“œ ë§¤ì¹­
    const emotionKeywords: Record<string, string[]> = {
      guilt: ['ì£„ì±…ê°', 'ë¯¸ì•ˆ', 'ì˜ëª»', 'í›„íšŒ', 'ë¶€ë„ëŸ½', 'guilty', 'sorry', 'regret'],
      anger: ['í™”', 'ì§œì¦', 'ë¶„ë…¸', 'ì—´ë°›', 'angry', 'mad', 'furious'],
      exhaustion: ['í”¼ê³¤', 'ì§€ì³', 'í˜ë“¤', 'ì§€ì¹¨', 'tired', 'exhausted', 'drained'],
      anxiety: ['ë¶ˆì•ˆ', 'ê±±ì •', 'ë‘ë µ', 'ì´ˆì¡°', 'anxious', 'worried', 'nervous'],
      sadness: ['ìŠ¬í”„', 'ìš°ìš¸', 'ì™¸ë¡œ', 'ëˆˆë¬¼', 'sad', 'depressed', 'lonely'],
      frustration: ['ë‹µë‹µ', 'ë§‰ë§‰', 'ì¢Œì ˆ', 'frustrated', 'stuck'],
    };

    let detectedEmotion = 'neutral';
    let maxMatches = 0;

    for (const [emotion, keywords] of Object.entries(emotionKeywords)) {
      const matches = keywords.filter((keyword) => lowerText.includes(keyword)).length;
      if (matches > maxMatches) {
        maxMatches = matches;
        detectedEmotion = emotion;
      }
    }

    // ë¶€ì •ì  ë‹¨ì–´ ì¹´ìš´íŠ¸ë¡œ ê°ì • ì ìˆ˜ ê³„ì‚°
    const negativeWords = [
      'ëª»',
      'ì•ˆ',
      'ë‚˜ìœ',
      'í˜•í¸ì—†',
      'ì‹¤íŒ¨',
      'ë¬¸ì œ',
      'í˜ë“¤',
      'bad',
      'terrible',
      'fail',
      'problem',
    ];
    const negativeCount = negativeWords.filter((word) => lowerText.includes(word)).length;

    const sentimentScore = Math.max(-1, -0.1 * negativeCount);
    const stressLevel = Math.min(10, Math.floor(negativeCount / 2) + 3);

    return {
      emotionalTone: detectedEmotion,
      sentimentScore,
      stressLevel,
    };
  }
}

export const claudeClient = new ClaudeClient();
